{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1aebd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564bacea",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'London.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import the dataset and check layout\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLondon.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df1\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'London.csv'"
     ]
    }
   ],
   "source": [
    "# Import the dataset and check layout\n",
    "df1 = pd.read_csv(\"/London.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d4f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for number of rows\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for number of locations\n",
    "len(df1.Location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab415a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cretaing a column for area code to better divide London locations\n",
    "df1['Area'] = df1['Postal Code'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59569c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking number of areas\n",
    "area_count =df1.groupby('Area')['Area'].agg('count').sort_values(ascending=False)\n",
    "area_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9931af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for areas with less than 10 properties\n",
    "len(area_count[area_count <= 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of areas with less than 10 properties\n",
    "area_less_than_10 = area_count[area_count <= 10]\n",
    "area_less_than_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn Areas with less than 10 properties into other area\n",
    "# df1.Location = df1.Location.apply(lambda x: 'other' if x in area_less_than_10 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394eb54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dccb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping null values\n",
    "# df2 = df1.dropna()\n",
    "# df2.isnull().sum()\n",
    "\n",
    "df2 =df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0438bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for any possible incorrectly input of data\n",
    "df2['No. of Bedrooms'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c41ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if properties with large numbers of bedrooms are valid\n",
    "df2.loc[df2['No. of Bedrooms'] > 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the reason for properties to have zero bedrooms\n",
    "df2.loc[df2['No. of Bedrooms'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e911a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing to see any incorrectly input area values\n",
    "df2['Area in sq ft'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e4c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to identify if values are a float (correct format)\n",
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11609391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Applying function to create a table of all values which are not float values \n",
    "df2[~df2['Area in sq ft'].apply(is_float)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe to create a price per squarefoot\n",
    "df3 = df2.copy()\n",
    "df3['Price per sqft'] =df3['Price']/df3['Area in sq ft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ee4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de329f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for propeties below threshold of 300 sq ft per bedroom\n",
    "df3[df3['Area in sq ft']/df3['No. of Bedrooms']<300].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a890dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers below threshold\n",
    "df4 = df3[~(df3['Area in sq ft']/df3['No. of Bedrooms']<300)]\n",
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2012ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers in Price per sq ft\n",
    "df4['Price per sqft'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffb135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to remove price per sq ft outliers of two standard deviations (outside 95%)\n",
    "def remove_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('Area'):\n",
    "        m = np.mean(subdf['Price per sqft'])\n",
    "        st = np.std(subdf['Price per sqft'])\n",
    "        reduced_df = subdf[(subdf['Price per sqft']>(m-2*st)) & (subdf['Price per sqft']<=(m+2*st))]\n",
    "        df_out = pd.concat([df_out,reduced_df], ignore_index=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143bf19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to dataframe\n",
    "df5 = remove_pps_outliers(df4)\n",
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64d3938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(df,location):\n",
    "    bedrooms2 = df[(df['Area']==location) & (df['No. of Bedrooms']==2)]\n",
    "    bedrooms3 = df[(df['Area']==location) & (df['No. of Bedrooms']==3)]\n",
    "    matplotlib.rcParams['figure.figsize'] = (15,10)\n",
    "    plt.scatter(bedrooms2['Area in sq ft'], bedrooms2['Price'], color ='blue', label = ' 2 Bedrooms', s=50)\n",
    "    plt.scatter(bedrooms3['Area in sq ft'], bedrooms3['Price'], color ='red', label = ' 3 Bedrooms', s=50)\n",
    "    plt.xlabel(\"Total Square Feet Area\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.title(location)\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304955a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(df5, 'SW11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20259582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bhk_outliers(df):\n",
    "    exclude_indices = np.array([])\n",
    "    for location, location_df in df.groupby('Area'):\n",
    "        bedrooms_stats = {}\n",
    "        for bedrooms, bedrooms_df in location_df.groupby('No. of Bedrooms'):\n",
    "            bedrooms_stats[bedrooms] = {\n",
    "                'mean': np.mean(bedrooms_df['Price per sqft']),\n",
    "                'std': np.std(bedrooms_df['Price per sqft'])*2,\n",
    "                'count': bedrooms_df.shape[0]\n",
    "            }\n",
    "        for bedrooms, bedrooms_df in location_df.groupby('No. of Bedrooms'):\n",
    "            stats = bedrooms_stats.get(bedrooms-1)\n",
    "            if stats and stats['count']>5:\n",
    "                exclude_indices = np.append(exclude_indices, bedrooms_df[bedrooms_df['Price per sqft']<(stats['mean'])].index.values)\n",
    "    return df.drop(exclude_indices,axis='index')\n",
    "df6 = remove_bhk_outliers(df5)\n",
    "\n",
    "df6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1410b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(df6, 'SW11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce046cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see where the majority of properties lay in terms of Size (Square Feet)\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.hist(df6[\"Price per sqft\"], rwidth =0.8)\n",
    "plt.xlabel(\"Price Per Sqaure Feet\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb6f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers in the amount of bathrooms in a property\n",
    "df6[\"No. of Bathrooms\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c12b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for properties outsdie the rule of a property not having the same numbers of bathrooms as bedrooms +2\n",
    "df6[df6[\"No. of Bathrooms\"]> df6[\"No. of Bedrooms\"]+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccce8cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selct only required columns for model\n",
    "df7 = df6.loc[:, ['Price','Area in sq ft','No. of Bedrooms', 'No. of Bathrooms', 'No. of Receptions', 'Area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b649ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categoric variable Area to be used for regression\n",
    "dummies = pd.get_dummies(df7.Area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e0195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the encoded 'Area' column to the original dataframe\n",
    "df8 = pd.concat([df7,dummies],axis = 'columns')\n",
    "df8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae883cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing original 'Area' column\n",
    "df9 = df8.drop('Area', axis ='columns')\n",
    "df9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ac554",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating X data without price as that is what is being predicted \n",
    "X = df9.drop('Price', axis='columns')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10650ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Creating y data made up of the property prices needed to be predicted\n",
    "y = df9.Price\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321767b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a testing and training datatset for the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d7f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the models accuracy \n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d78768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrying out cross validation to measure the accuracy of the model\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(LinearRegression(), X, y, cv=cv)\n",
    "\n",
    "# Negative values can be ignored and positive values lie between 69.5% and 80.9% acccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eac238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best model between lasso regression and decsiion tree using GridSearchCV to perform hyper-parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def find_best_model_using_gridsearchcv(X,y):\n",
    "    algos = {       \n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1,2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion' : ['mse','friedman_mse'],\n",
    "                'splitter': ['best','random']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    for algo_name, config in algos.items():\n",
    "        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n",
    "        gs.fit(X,y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "\n",
    "find_best_model_using_gridsearchcv(X,y)\n",
    "\n",
    "# From the results the lasso regression model is the most accurate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the lasso regression model with the optimum parameters\n",
    "lrm = Lasso(alpha=1.0, selection = 'random', tol=1e-1)\n",
    "lrm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to create a price predicition\n",
    "def predict_price(Area,sqft,bed,bath,rec):\n",
    "    loc_index = np.where(X.columns==Area)[0][0]\n",
    "\n",
    "    x = np.zeros(len(X.columns))\n",
    "    x[0] = sqft\n",
    "    x[1] = bed\n",
    "    x[2] = bath\n",
    "    x[3] = rec\n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] = 1\n",
    "\n",
    "    return lrm.predict([x])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4242b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the price predictor\n",
    "predict_price('SW11',1000,2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd606bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('londonhouse__prices_model.pickle','wb') as f:\n",
    "    pickle.dump(lrm,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161c217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
